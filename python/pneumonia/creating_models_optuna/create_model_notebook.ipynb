{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import optuna\n",
    "import math\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mason/Documents/school/machine_learning/projects/applied_project/0xDEADBEEFCAFE/python/pneumonia/creating_models_optuna'\n",
    "data_path = path + \"/../data\"\n",
    "test_data_filepath = data_path + \"/test\"\n",
    "train_data_filepath = data_path + \"/train\"\n",
    "val_data_filepath = data_path + \"/val\"\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 20\n",
    "NUM_TRAIN_SAMPLES = 1341 + 3875 # Normal + Pneumonia\n",
    "NUM_VAL_SAMPLES = 8 + 8 # Normal + Pneumonia\n",
    "\n",
    "INPUT_SHAPE = (255, 255, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    train_gen = ImageDataGenerator( rescale=1./255,\n",
    "                                    shear_range= 0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "    val_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_set = train_gen.flow_from_directory(  train_data_filepath,\n",
    "                                                target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                class_mode='binary')\n",
    "\n",
    "    val_set = val_gen.flow_from_directory(  val_data_filepath,\n",
    "                                            target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            class_mode='binary')\n",
    "\n",
    "    test_gen = ImageDataGenerator(rescale= 1./255)\n",
    "    test_set = test_gen.flow_from_directory(  test_data_filepath,\n",
    "                                                target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                class_mode='binary')\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First Convolutional Layer\n",
    "    model.add(\n",
    "        Conv2D( filters=trial.suggest_categorical('filters_1', [16, 32, 64, 128]),\n",
    "                kernel_size=trial.suggest_categorical('kernel_size_1', [2, 3, 4]),\n",
    "                input_shape=INPUT_SHAPE,\n",
    "                activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(trial.suggest_uniform('dropout_1', 0.0, 1.0)))\n",
    "\n",
    "    # Second Convolutional Layer\n",
    "    model.add(\n",
    "        Conv2D( filters=trial.suggest_categorical('filters_2', [16, 32, 64, 128]),\n",
    "                kernel_size=trial.suggest_categorical('kernel_size_2', [2, 3, 4]),\n",
    "                activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(trial.suggest_uniform('dropout_2', 0.0, 1.0)))\n",
    "\n",
    "    # Third Convolutional Layer\n",
    "    model.add(\n",
    "        Conv2D( filters=trial.suggest_categorical('filters_3', [16, 32, 64, 128]),\n",
    "                kernel_size=trial.suggest_categorical('kernel_size_3', [2, 3, 4]),\n",
    "                activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(trial.suggest_uniform('dropout_3', 0.0, 1.0)))\n",
    "\n",
    "    # Fourth Convolutional Layer\n",
    "    if trial.suggest_categorical('Fourth Layer', [True, False]):\n",
    "        model.add(\n",
    "            Conv2D( filters=trial.suggest_categorical('filters_4', [16, 32, 64, 128]),\n",
    "                    kernel_size=trial.suggest_categorical('kernel_size_4', [2, 3, 4]),\n",
    "                    activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(trial.suggest_uniform('dropout_4', 0.0, 1.0)))\n",
    "\n",
    "    # Feed forward network ----------\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(trial.suggest_categorical('dense_layer_nodes_1', [16, 32, 64]), activation='relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    model.fit_generator(train_set,\n",
    "                        steps_per_epoch=int(NUM_TRAIN_SAMPLES/BATCH_SIZE),\n",
    "                        nb_epoch=NUM_EPOCHS,\n",
    "                        validation_data=val_set,\n",
    "                        validation_steps=math.ceil(NUM_VAL_SAMPLES / BATCH_SIZE))\n",
    "  \n",
    "    accuracy = model.evaluate_generator(test_set)[1]\n",
    "    \n",
    "    model.save(path + '/' + 'models/model_' + str(int(accuracy * 100 * 100)) + '_' + str(int(math.ceil(time.time()))) + '.h5')\n",
    "\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials = 20)\n",
    "optuna.visualization.plot_optimization_history(study)\n",
    "optuna.visualization.plot_contour(study)\n",
    "optuna.visualization.plot_intermediate_values(study)\n",
    "optuna.visualization.plot_slice(study)\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  }
 ]
}